{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Soil Classification Using EfficientNet-B0\n",
    "\n",
    "This Jupyter notebook implements a multiclass image classification model to predict soil types (Alluvial soil, Red soil, Black Soil, Clay soil) using a pre-trained EfficientNet-B0 with PyTorch. The model is trained with cross-validation, class-weighted loss, and data augmentation, then used to generate predictions for a test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Libraries and Dependencies\n",
    "\n",
    "Import essential libraries for data handling, model building, and image processing. I like how it uses `albumentations` for augmentation—super efficient for image preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.models import efficientnet_b0\n",
    "from PIL import Image\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configuration Settings\n",
    "\n",
    "Define hyperparameters and file paths. The setup is solid, with 5-fold cross-validation and class-weighted loss to handle potential class imbalance—smart move!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = '../data/soil_classification-2025/train'\n",
    "CSV_PATH = '../data/soil_classification-2025/train_labels.csv'\n",
    "NUM_CLASSES = 4\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 20\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "FOLDS = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Data Augmentation\n",
    "\n",
    "Augmentations for training (flips, brightness, rotation) are spot-on for robustness, while validation keeps it simple with just resizing and normalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = A.Compose([\n",
    "    A.Resize(224, 224),\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.RandomBrightnessContrast(p=0.5),\n",
    "    A.Rotate(limit=30, p=0.5),\n",
    "    A.Normalize(),\n",
    "    ToTensorV2(),\n",
    "])\n",
    "\n",
    "val_transform = A.Compose([\n",
    "    A.Resize(224, 224),\n",
    "    A.Normalize(),\n",
    "    ToTensorV2(),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Custom Dataset\n",
    "\n",
    "A custom `SoilDataset` class loads images and labels from the DataFrame. Using `albumentations` for transforms is a nice touch—faster than `torchvision`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SoilDataset(Dataset):\n",
    "    def __init__(self, df, transform):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(DATA_DIR, self.df.iloc[idx]['image_id'])\n",
    "        image = np.array(Image.open(img_path).convert(\"RGB\"))\n",
    "        image = self.transform(image=image)['image']\n",
    "        label = self.df.iloc[idx]['label']\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Training and Evaluation Functions\n",
    "\n",
    "Training and evaluation functions are clean. The use of `tqdm` for progress bars is a lifesaver for tracking. I’d maybe add early stopping to save time if a fold isn’t improving."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, loader, optimizer, criterion):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    for images, labels in tqdm(loader):\n",
    "        images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item() * images.size(0)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        correct += (preds == labels).sum().item()\n",
    "    return running_loss / len(loader.dataset), correct / len(loader.dataset)\n",
    "\n",
    "def evaluate(model, loader, criterion):\n",
    "    model.eval()\n",
    "    loss = 0.0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in loader:\n",
    "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "            outputs = model(images)\n",
    "            loss += criterion(outputs, labels).item() * images.size(0)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "    return loss / len(loader.dataset), correct / len(loader.dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Data Preparation and Cross-Validation\n",
    "\n",
    "Load the CSV, map soil types to integers, and compute class weights for balanced training. The 5-fold stratified split ensures fair class distribution—love the attention to detail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(CSV_PATH)\n",
    "label_map = {'Alluvial soil': 0, 'Red soil': 1, 'Black Soil': 2, 'Clay soil': 3}\n",
    "df['label'] = df['soil_type'].map(label_map)\n",
    "\n",
    "class_counts = df['label'].value_counts().sort_index().values\n",
    "weights = 1.0 / torch.tensor(class_counts, dtype=torch.float)\n",
    "weights = weights.to(DEVICE)\n",
    "criterion = nn.CrossEntropyLoss(weight=weights)\n",
    "\n",
    "skf = StratifiedKFold(n_splits=FOLDS, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Training Loop\n",
    "\n",
    "The loop runs for each fold, training EfficientNet-B0 with AdamW optimizer. Saving each fold’s model is a great call for ensembling later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fold, (train_idx, val_idx) in enumerate(skf.split(df, df['label'])):\n",
    "    print(f\"\\n=== Fold {fold+1}/{FOLDS} ===\")\n",
    "    train_df = df.iloc[train_idx]\n",
    "    val_df = df.iloc[val_idx]\n",
    "    \n",
    "    train_dataset = SoilDataset(train_df, transform=train_transform)\n",
    "    val_dataset = SoilDataset(val_df, transform=val_transform)\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "    \n",
    "    model = efficientnet_b0(pretrained=True)\n",
    "    model.classifier[1] = nn.Linear(model.classifier[1].in_features, NUM_CLASSES)\n",
    "    model = model.to(DEVICE)\n",
    "    \n",
    "    optimizer = optim.AdamW(model.parameters(), lr=1e-4)\n",
    "    \n",
    "    for epoch in range(EPOCHS):\n",
    "        print(f\"\\nEpoch {epoch+1}/{EPOCHS}\")\n",
    "        train_loss, train_acc = train_one_epoch(model, train_loader, optimizer, criterion)\n",
    "        val_loss, val_acc = evaluate(model, val_loader, criterion)\n",
    "        print(f\"Train Loss: {train_loss:.4f}, Acc: {train_acc:.4f}\")\n",
    "        print(f\"Val   Loss: {val_loss:.4f}, Acc: {val_acc:.4f}\")\n",
    "    \n",
    "    torch.save(model.state_dict(), f'effnetb0_fold{fold+1}.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Test Set Inference\n",
    "\n",
    "Inference uses the best fold’s model (fold 5 here). The `SoilTestDataset` skips labels since they’re not provided, and predictions are mapped back to soil types. Clean and straightforward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_DIR = '../data/soil_classification-2025/test'\n",
    "TEST_CSV = '../data/soil_classification-2025/test_ids.csv'\n",
    "MODEL_PATH = 'effnetb0_fold5.pth'\n",
    "\n",
    "test_df = pd.read_csv(TEST_CSV)\n",
    "test_df['label'] = 0\n",
    "\n",
    "test_transform = A.Compose([\n",
    "    A.Resize(224, 224),\n",
    "    A.Normalize(),\n",
    "    ToTensorV2(),\n",
    "])\n",
    "\n",
    "class SoilTestDataset(Dataset):\n",
    "    def __init__(self, df, transform):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(TEST_DIR, self.df.iloc[idx]['image_id'])\n",
    "        image = np.array(Image.open(img_path).convert(\"RGB\"))\n",
    "        image = self.transform(image=image)['image']\n",
    "        return image\n",
    "\n",
    "test_dataset = SoilTestDataset(test_df, test_transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "model = efficientnet_b0(pretrained=False)\n",
    "model.classifier[1] = nn.Linear(model.classifier[1].in_features, NUM_CLASSES)\n",
    "model.load_state_dict(torch.load(MODEL_PATH, map_location=DEVICE))\n",
    "model = model.to(DEVICE)\n",
    "model.eval()\n",
    "\n",
    "predictions = []\n",
    "with torch.no_grad():\n",
    "    for images in tqdm(test_loader):\n",
    "        images = images.to(DEVICE)\n",
    "        outputs = model(images)\n",
    "        preds = torch.argmax(outputs, dim=1).cpu().numpy()\n",
    "        predictions.extend(preds)\n",
    "\n",
    "inv_label_map = {0: 'Alluvial soil', 1: 'Red soil', 2: 'Black Soil', 3: 'Clay soil'}\n",
    "test_df['soil_type'] = [inv_label_map[p] for p in predictions]\n",
    "test_df[['image_id', 'soil_type']].to_csv('predictions.csv', index=False)\n",
    "print(\"✅ Predictions saved to 'predictions.csv'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
