{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Soil Classification Using ResNet18\n","\n","This Jupyter notebook implements a binary image classification model to distinguish soil images from non-soil images (CIFAR-10 and MNIST datasets). The model uses a pre-trained ResNet18 with PyTorch, fine-tuned for the task. The code includes data loading, preprocessing, model training, and generating predictions for a test set.\n"]},{"cell_type":"markdown","metadata":{},"source":["## 1. Import Libraries and Dependencies\n","\n","Importing necessary libraries for data handling, model building, and image processing."]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[],"source":["import os\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score\n","import torch\n","import torch.nn as nn\n","from torch.utils.data import Dataset, DataLoader\n","from torchvision import transforms, models\n","from PIL import Image\n","import warnings\n","\n","warnings.filterwarnings('ignore')\n"]},{"cell_type":"markdown","metadata":{},"source":["## 2. Configuration Settings\n","\n","Define hyperparameters and paths for the experiment."]},{"cell_type":"markdown","metadata":{},"source":["### 2.1 Hyperparameters"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["BATCH_SIZE = 32\n","EPOCHS = 10\n","LR = 1e-4\n","IMG_SIZE = 224\n","DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"]},{"cell_type":"markdown","metadata":{},"source":["### 2.2 File Paths"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["soil_root = '../data/soil_competition-2025'  # Soil dataset path\n","cifar_root = '../data/cifar10/test'  # CIFAR-10 dataset path\n","mnist_root = '../data/mnist_png/testing'  # MNIST dataset path"]},{"cell_type":"markdown","metadata":{},"source":["## 3. Data Preparation\n","\n","Load and preprocess the soil, CIFAR-10, and MNIST datasets, merging them into a single DataFrame."]},{"cell_type":"markdown","metadata":{},"source":["### 3.1 Load Soil Data (Label = 1)"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["df_soil = pd.read_csv(os.path.join(soil_root, 'train_labels.csv'))\n","df_soil['path'] = df_soil['image_id'].apply(lambda x: os.path.join(soil_root, 'train', x))\n","df_soil['label'] = 1  # Soil images are labeled as 1"]},{"cell_type":"markdown","metadata":{},"source":["### 3.2 Load CIFAR-10 Data (Label = 0, 120 samples per class)\n"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":["cifar_data = []\n","for cls in os.listdir(cifar_root):\n","    cls_path = os.path.join(cifar_root, cls)\n","    imgs = os.listdir(cls_path)[:120]  # Limit to 120 images per class\n","    for img in imgs:\n","        cifar_data.append({\n","            'image_id': img,\n","            'path': os.path.join(cls_path, img),\n","            'label': 0  # Non-soil images are labeled as 0\n","        })\n","df_cifar = pd.DataFrame(cifar_data)"]},{"cell_type":"markdown","metadata":{},"source":["### 3.3 Load MNIST Data (Label = 0, 80 samples per class)\n"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["mnist_data = []\n","for cls in os.listdir(mnist_root):\n","    cls_path = os.path.join(mnist_root, cls)\n","    imgs = os.listdir(cls_path)[:80]  # Limit to 80 images per class\n","    for img in imgs:\n","        mnist_data.append({\n","            'image_id': img,\n","            'path': os.path.join(cls_path, img),\n","            'label': 0  # Non-soil images are labeled as 0\n","        })\n","df_mnist = pd.DataFrame(mnist_data)"]},{"cell_type":"markdown","metadata":{},"source":["### 3.4 Merge and Split Data\n"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[],"source":["df_all = pd.concat([df_soil[['image_id', 'path', 'label']], df_cifar, df_mnist], ignore_index=True)\n","df_train, df_val = train_test_split(df_all, test_size=0.2, stratify=df_all['label'], random_state=42)"]},{"cell_type":"markdown","metadata":{},"source":["## 4. Custom Dataset and DataLoaders\n","\n","Define a custom dataset class and set up data transformations and DataLoaders."]},{"cell_type":"markdown","metadata":{},"source":["### 4.1 Custom Dataset Class\n"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[],"source":["class CombinedDataset(Dataset):\n","    def __init__(self, df, transform=None):\n","        self.df = df.reset_index(drop=True)\n","        self.transform = transform\n","\n","    def __len__(self):\n","        return len(self.df)\n","\n","    def __getitem__(self, idx):\n","        image = Image.open(self.df.iloc[idx]['path']).convert(\"RGB\")\n","        label = self.df.iloc[idx]['label']\n","        if self.transform:\n","            image = self.transform(image)\n","        return image, torch.tensor(label, dtype=torch.float32)"]},{"cell_type":"markdown","metadata":{},"source":["### 4.2 Data Transformations\n"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[],"source":["train_transform = transforms.Compose([\n","    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n","    transforms.RandomHorizontalFlip(),  # Data augmentation\n","    transforms.RandomRotation(20),      # Data augmentation\n","    transforms.ColorJitter(brightness=0.2, contrast=0.2),  # Data augmentation\n","    transforms.ToTensor(),\n","    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])  # ImageNet normalization\n","])\n","\n","test_transform = transforms.Compose([\n","    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n","    transforms.ToTensor(),\n","    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])  # ImageNet normalization\n","])"]},{"cell_type":"markdown","metadata":{},"source":["### 4.3 DataLoaders\n"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[],"source":["train_ds = CombinedDataset(df_train, transform=train_transform)\n","val_ds = CombinedDataset(df_val, transform=test_transform)\n","\n","train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True)\n","val_loader = DataLoader(val_ds, batch_size=BATCH_SIZE)"]},{"cell_type":"markdown","metadata":{},"source":["## 5. Model Setup\n","\n","Initialize and configure the ResNet18 model for binary classification."]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[],"source":["model = models.resnet18(pretrained=True)  # Use pre-trained weights\n","model.fc = nn.Linear(model.fc.in_features, 1)  # Modify final layer for binary output\n","model = model.to(DEVICE)\n","\n","criterion = nn.BCEWithLogitsLoss()  # Loss function for binary classification\n","optimizer = torch.optim.Adam(model.parameters(), lr=LR)  # Adam optimizer\n","scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=2)  # Learning rate scheduler"]},{"cell_type":"markdown","metadata":{},"source":["## 6. Training Loop\n","\n","Train the model and evaluate on the validation set for each epoch."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["for epoch in range(EPOCHS):\n","    model.train()\n","    total_loss = 0\n","    for images, labels in train_loader:\n","        images, labels = images.to(DEVICE), labels.to(DEVICE).unsqueeze(1)\n","        outputs = model(images)\n","        loss = criterion(outputs, labels)\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","        total_loss += loss.item()\n","    avg_train_loss = total_loss / len(train_loader)\n","\n","    # Validation\n","    model.eval()\n","    preds, true = [], []\n","    with torch.no_grad():\n","        for images, labels in val_loader:\n","            images = images.to(DEVICE)\n","            outputs = torch.sigmoid(model(images)).cpu().numpy()\n","            preds.extend(outputs)\n","            true.extend(labels.numpy())\n","    preds = [1 if p > 0.5 else 0 for p in preds]\n","    acc = accuracy_score(true, preds)\n","    scheduler.step(1 - acc)\n","    print(f\"Epoch {epoch+1}: Loss {avg_train_loss:.4f}, Val Acc {acc:.4f}\")"]},{"cell_type":"markdown","metadata":{},"source":["## 7. Generate Predictions for Test Set\n","\n","Load test data and generate predictions for submission."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["test_root = '../data/soil_competition-2025/test'\n","test_ids = pd.read_csv('../data/soil_competition-2025/test_ids.csv')\n","\n","model.eval()\n","preds = []\n","\n","for img_name in test_ids['image_id']:\n","    img_path = os.path.join(test_root, img_name)\n","    img = Image.open(img_path).convert(\"RGB\")\n","    img = test_transform(img).unsqueeze(0).to(DEVICE)\n","    with torch.no_grad():\n","        output = torch.sigmoid(model(img)).item()\n","        pred = 1 if output > 0.5 else 0\n","        preds.append(pred)\n","\n","# Save predictions to CSV\n","submission = pd.DataFrame({\n","    'image_id': test_ids['image_id'],\n","    'label': preds\n","})\n","submission.to_csv('submission.csv', index=False)\n","print(\"âœ… submission.csv saved\")"]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"databundleVersionId":12412856,"isSourceIdPinned":false,"sourceId":102966,"sourceType":"competition"},{"datasetId":27469,"sourceId":35012,"sourceType":"datasetVersion"},{"datasetId":1856924,"sourceId":3032274,"sourceType":"datasetVersion"}],"dockerImageVersionId":31041,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"venv","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.13.3"}},"nbformat":4,"nbformat_minor":4}
